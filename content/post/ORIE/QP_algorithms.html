---
title: "Quadratic Programming Examples and Algorithms"
author: "Erick Jones"
date: 2020-01-07
categories: ["ORIE Techniques"]
tags: ["R Markdown", "QP", "Interior Point", "Algorithms"]
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<p>This post explores how to solve QPs by hand and with Gurobi.
I have written these using Gurobi as a solver and as the mathematical formulation software.
This is a reproducible example if you have R Studio just make sure you have installed the correct packages.</p>
<pre class="r"><code>library(gurobi)</code></pre>
<pre><code>## Warning: package &#39;gurobi&#39; was built under R version 4.0.2</code></pre>
<pre class="r"><code>library(tictoc)
library(Matrix)
library(ggplot2)</code></pre>
<pre><code>## Warning: package &#39;ggplot2&#39; was built under R version 4.0.2</code></pre>
<pre class="r"><code>#library(matlib)
library(MASS)</code></pre>
<pre><code>## Warning: package &#39;MASS&#39; was built under R version 4.0.2</code></pre>
<p>Gradient Descent a first order method <span class="math inline">\(x_{i+1} = x_i + \lambda*d/f(x)\)</span></p>
<pre class="r"><code>x &lt;- c(-10:10)
fx1 &lt;- x^2
xi &lt;- 10
lambda &lt;- 0.2
xit &lt;- xi

fx &lt;- xit^2
dfx &lt;- 2*xit

gd &lt;- data.frame(&#39;x&#39; = xit, &#39;fx&#39; = fx, &#39;dfx&#39; = dfx)



while(dfx &lt; -10^-50 | dfx &gt; 10^-50){
xit &lt;- xit - lambda*dfx
fx &lt;- xit^2
dfx &lt;- 2*xit
gd &lt;- rbind(gd, c(xit,fx,dfx))

}

head(gd)</code></pre>
<pre><code>##         x          fx     dfx
## 1 10.0000 100.0000000 20.0000
## 2  6.0000  36.0000000 12.0000
## 3  3.6000  12.9600000  7.2000
## 4  2.1600   4.6656000  4.3200
## 5  1.2960   1.6796160  2.5920
## 6  0.7776   0.6046618  1.5552</code></pre>
<pre class="r"><code>tail(gd)</code></pre>
<pre><code>##                x            fx          dfx
## 228 4.368515e-50  1.908392e-99 8.737030e-50
## 229 2.621109e-50 6.870213e-100 5.242218e-50
## 230 1.572665e-50 2.473277e-100 3.145331e-50
## 231 9.435993e-51 8.903795e-101 1.887199e-50
## 232 5.661596e-51 3.205366e-101 1.132319e-50
## 233 3.396957e-51 1.153932e-101 6.793915e-51</code></pre>
<pre class="r"><code>qplot(x = x, y = fx1)</code></pre>
<p><img src="/post/ORIE/QP_algorithms_files/figure-html/gradient_descent_example-1.png" width="672" /></p>
<pre class="r"><code>qplot(x,fx, data = gd)</code></pre>
<p><img src="/post/ORIE/QP_algorithms_files/figure-html/gradient_descent_example-2.png" width="672" /></p>
<p>standard form for quadratics</p>
<p><span class="math inline">\(min\: z; z = -8x_1-16x_2+x_1^2+4x_2^2\)</span></p>
<p>s.t.
<span class="math inline">\(x_1 + x_2 + x_3 = 5\)</span>
<span class="math inline">\(x_1 + x_4 = 3\)</span>
From Jensen and Bard Quadratic Solver notes in Book
Idea given A,b,c and intial value of x; find optimal x that minimizes câ€™*x</p>
<pre class="r"><code>constr1 &lt;- c(1,1,1,0)
constr2 &lt;- c(1,0,0,1)


A &lt;- rbind(constr1,constr2)

m &lt;- nrow(A)
n &lt;- ncol(A)


b &lt;- matrix(c(5,3),nrow =m)
c &lt;- matrix(c(-8,-16,0,0), nrow = n)
Q &lt;- rbind(c(2,0,0,0),c(0,8,0,0),c(0,0,0,0),c(0,0,0,0))
#inital x values (xi) given by slacks = RHS
xi &lt;- matrix(c(1,1,0.5,0.5), nrow =n)

m &lt;- nrow(A)
n &lt;- ncol(A)

I &lt;- diag(n)
z1 &lt;- matrix(rep(0,n*n), nrow = n)
z2 &lt;- matrix(rep(0,m*m), nrow = m)
z3 &lt;- matrix(rep(0,m*n), nrow = m)
y &lt;- matrix(rep(1,m), nrow = n)
#The complimentary slackness modifier 1/t eventually goes to 0 as t &gt;&gt;&gt;&gt; inf
t &lt;- 9
#Step size pretty much make it up
alpha &lt;- 0.1
#mu*x = 0 in complemntariy slackness condition , mu &gt;0 is dual condition mu correspond to dual variables, 
#using fancy vectors this gives Xd*mu = XM1 = 1/t where t &gt;&gt;&gt;&gt; inf 
x &lt;- xi
mu &lt;- x/t
mu_minus_c &lt;- mu - c - Q%*%x
#Gives lagrangian multipliers for constraints
#Solving c+A*lamda-mu = 0 gives initial lambda
lambda &lt;- ginv(t(A))%*%(mu_minus_c)


#combined vector having values of x, lambda, and mu useful when adding the search direction
w &lt;- rbind(x, lambda, mu)


#This is the KKT condition stationarity, at optimality this derivative should  be 0,
#Using the lagrangian cx+lambda*Ax-mu &gt;&gt; c+A*lambda-mu
c_plus_tA &lt;- Q%*%x+c+t(A)%*%lambda-mu

#This is the KKT condition primal feasiblity, this should always be 0 Ax-b=0 
A_times_x_minus_b &lt;- A%*%x-b

#This is the modfied complimentary condtion XM1 -1/t = 0 X is the diag(x) and M is diag(mu) 1/t &gt;&gt;&gt; 0 as t gets larger
x_times_mu_minus_y_over_t &lt;- x*mu-y/t

#The right hand side of the search direction iteration given from the Newton-Raphson Method
#Combines the vectors above
B &lt;- rbind(c_plus_tA,A_times_x_minus_b,x_times_mu_minus_y_over_t)

objective &lt;- 0.5*t(x)%*%Q%*%x+t(c)%*%x
error &lt;- norm(B,&#39;2&#39;)

iteration_list &lt;- data.frame(&#39;x1&#39; = x[1], &#39;x2&#39; = x[2], &#39;x3&#39; = x[3], &#39;x4&#39; = x[4], &#39;objective&#39; = objective, &#39;error&#39; = error)

#loop



while(error &gt; 10^-12){
t &lt;- t*9

Xd = Diagonal(n = n, x)

Mud = Diagonal(n = n, mu) 


#The left hand side matrix of the search direction iteration, it containtes information from the A, x, and mu vectors and matricies of 1s or 0s to make the math make sense

C &lt;- rbind(cbind(Q,t(A),-I),cbind(A,z2,z3), cbind(Mud,t(z3), Xd))

#The right hand side of the search direction iteration given from the Newton-Raphson Method
#This contains the objective function costs, the RHS values, as well as the A, x, and mu vectors. 
#It also has the complimentary condition represented by t
B &lt;- rbind(Q%*%x+c+t(A)%*%lambda-mu,A%*%x-b,x*mu-y/t)


#solving the systems of equations with C and B gives the search direction as you move closer and closer to solving the complimentary condition in the KKT conditions
dw = solve(-C,B)


#update your w vector which is just a list of the x, mu, and lambda vectors using the search direction
w &lt;- w + alpha*dw

x &lt;- w[1:n]

lambda &lt;- w[(n+1):(n+m)]

mu &lt;- w[(n+m+1):length(w)]

#calculate the objective function from the x values and the error. Remember if this satisifies all the KKT conditions then the B vector will be 0.
objective &lt;- 0.5*t(x)%*%Q%*%x+t(c)%*%x
error &lt;- norm(B,&#39;2&#39;)
iteration_list &lt;- rbind(iteration_list,c(x,objective,error))

}

head(iteration_list)</code></pre>
<pre><code>##         x1       x2         x3         x4 objective    error
## 1 1.000000 1.000000 0.50000000 0.50000000 -19.00000 6.520410
## 2 1.269990 1.096877 0.38313300 0.38001002 -21.28452 6.520877
## 3 1.516786 1.183938 0.27427586 0.26821381 -23.16982 5.868998
## 4 1.734188 1.261642 0.18166935 0.17231180 -24.68541 5.282035
## 5 1.918400 1.330365 0.11098503 0.09745009 -25.87330 4.753769
## 6 2.066579 1.390789 0.06640714 0.04768647 -26.77733 4.278347</code></pre>
<pre class="r"><code>tail(iteration_list)</code></pre>
<pre><code>##     x1 x2           x3           x4 objective        error
## 278  3  2 3.020886e-08 5.122922e-16       -31 1.531109e-12
## 279  3  2 2.869842e-08 4.610630e-16       -31 1.377965e-12
## 280  3  2 2.726350e-08 4.149567e-16       -31 1.239794e-12
## 281  3  2 2.590032e-08 3.734610e-16       -31 1.115852e-12
## 282  3  2 2.460531e-08 3.361149e-16       -31 1.003790e-12
## 283  3  2 2.337504e-08 3.025034e-16       -31 9.038590e-13</code></pre>
<p>standard form for quadratics
<span class="math inline">\(min \:z; z = 4x_1^2 + 4x_2^2 - 2x_1x_2 - 12x_1 - 72x_2 + 384\)</span>
s.t.
<span class="math inline">\(2x_1 + x_2 + x_3 = 18\)</span>
<span class="math inline">\(6x_1+ 5x_2 + x_4 = 60\)</span>
<span class="math inline">\(2x_1 + 5x_2 + x_5 = 40\)</span></p>
<pre class="r"><code>#Another example from http://fourier.eng.hmc.edu/e176/lectures/ch3/node19.html, but don&#39;t have answers 



#Work out matricies in Wolfram Alpha

#Idea given A,b,c and intial value of x; find optimal x that minimizes c&#39;*x

constr1 &lt;- c(2,1,1,0,0)
constr2 &lt;- c(6,5,0,1,0)
constr3 &lt;- c(2,5,0,0,1)

A &lt;- rbind(constr1,constr2, constr3)

b &lt;- matrix(c(18,60,40),nrow =3)
c &lt;- matrix(c(-8,-16,0,0,0), nrow = 5)
Q &lt;- rbind(c(2,1,0,0,0),c(1,2,0,0,0),c(0,0,0,0,0),c(0,0,0,0,0),c(0,0,0,0,0))

rm(A,b,c,Q,constr1,constr2,constr3)</code></pre>
<p>Add a new chunk by clicking the <em>Insert Chunk</em> button on the toolbar or by pressing <em>Ctrl+Alt+I</em>.</p>
<p>When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the <em>Preview</em> button or press <em>Ctrl+Shift+K</em> to preview the HTML file).</p>
<p>The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike <em>Knit</em>, <em>Preview</em> does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.</p>
